{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"18ERMgSm4VIBzrPHGOQQ9u_x6MmCzpFpU","authorship_tag":"ABX9TyNGOR7YHRFP2tlsvVM5XLFA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"cJwXoVBZnNRA","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1BU5Bqb8gDTaHZ_1vE9-fR-_lGEef7sjK"},"executionInfo":{"status":"ok","timestamp":1720209576260,"user_tz":-330,"elapsed":12391053,"user":{"displayName":"PRAJAPATI ANANDKUMAR VALABHAI","userId":"02249163125110266938"}},"outputId":"8ad77a2c-180c-4c47-f908-5c6a86db375b"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Define the generator model\n","def build_generator(latent_dim, num_channels):\n","    model = models.Sequential()\n","    model.add(layers.Dense(128 * 16 * 16, input_dim=latent_dim))\n","    model.add(layers.LeakyReLU(alpha=0.2))\n","    model.add(layers.Reshape((16, 16, 128)))\n","    model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","    model.add(layers.LeakyReLU(alpha=0.2))\n","    model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","    model.add(layers.LeakyReLU(alpha=0.2))\n","    model.add(layers.Conv2D(num_channels, (3,3), activation='tanh', padding='same'))\n","    return model\n","\n","# Define the discriminator model\n","def build_discriminator(input_shape):\n","    model = models.Sequential()\n","    model.add(layers.Conv2D(64, (3,3), strides=(2,2), padding='same', input_shape=input_shape))\n","    model.add(layers.LeakyReLU(alpha=0.2))\n","    model.add(layers.Dropout(0.4))\n","    model.add(layers.Conv2D(128, (3,3), strides=(2,2), padding='same'))\n","    model.add(layers.LeakyReLU(alpha=0.2))\n","    model.add(layers.Dropout(0.4))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(1, activation='sigmoid'))\n","    return model\n","\n","# Build and compile the discriminator\n","image_shape = (64, 64, 3)  # Adjust according to your image dimensions\n","discriminator = build_discriminator(image_shape)\n","discriminator.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5), metrics=['accuracy'])\n","\n","# Build the generator\n","latent_dim = 100  # Dimensionality of the latent space\n","generator = build_generator(latent_dim, image_shape[-1])\n","\n","# The generator takes noise as input and generates images\n","z = layers.Input(shape=(latent_dim,))\n","image = generator(z)\n","\n","# For the combined model, only train the generator\n","discriminator.trainable = False\n","\n","# The discriminator takes generated images as input and determines validity\n","validity = discriminator(image)\n","\n","# The combined model (stacked generator and discriminator)\n","combined = models.Model(z, validity)\n","combined.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(0.0002, 0.5))\n","\n","# Define function to generate and save images\n","def generate_and_save_images(generator, epoch, latent_dim, num_examples_to_generate=16):\n","    noise = np.random.normal(0, 1, (num_examples_to_generate, latent_dim))\n","    generated_images = generator.predict(noise)\n","\n","    plt.figure(figsize=(10, 10))\n","    for i in range(num_examples_to_generate):\n","        plt.subplot(4, 4, i + 1)\n","        plt.imshow(generated_images[i] * 0.5 + 0.5)  # De-normalize the image\n","        plt.axis('off')\n","\n","    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n","    plt.show()\n","\n","# Load your dataset and preprocessing steps\n","def load_data(dataset_dir, image_size=(64, 64), batch_size=32):\n","    datagen = ImageDataGenerator(rescale=1./255)\n","    data_generator = datagen.flow_from_directory(\n","        dataset_dir,\n","        target_size=image_size,\n","        batch_size=batch_size,\n","        class_mode=None,\n","        shuffle=True\n","    )\n","    return data_generator\n","\n","# Training parameters\n","epochs = 500\n","batch_size = 32\n","latent_dim = 100  # Dimensionality of the latent space\n","dataset_dir = '/content/drive/MyDrive/dataset'  # Replace with the path to your Market-1501 dataset directory\n","\n","# Train the GAN\n","data_generator = load_data(dataset_dir, batch_size=batch_size)\n","steps_per_epoch = data_generator.samples // batch_size\n","for epoch in range(epochs):\n","    d_losses = []\n","    g_losses = []\n","    for step in range(steps_per_epoch):\n","        images = data_generator.next()\n","        num_samples = images.shape[0]\n","        # Adversarial ground truths\n","        valid = np.ones((num_samples, 1))\n","        fake = np.zeros((num_samples, 1))\n","\n","        # Train discriminator\n","        noise = np.random.normal(0, 1, (num_samples, latent_dim))\n","        gen_images = generator.predict(noise)\n","\n","        d_loss_real = discriminator.train_on_batch(images, valid)\n","        d_loss_fake = discriminator.train_on_batch(gen_images, fake)\n","        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","        d_losses.append(d_loss)\n","\n","        # Train generator\n","        noise = np.random.normal(0, 1, (num_samples, latent_dim))\n","        g_loss = combined.train_on_batch(noise, valid)\n","        g_losses.append(g_loss)\n","\n","    # Print progress after each epoch\n","    print(f\"Epoch {epoch + 1}/{epochs}, D Loss: {np.mean(d_losses, axis=0)[0]}, G Loss: {np.mean(g_losses)}\")\n","\n","    # Optionally, save and display generated images\n","    if epoch % 10 == 0:\n","        generate_and_save_images(generator, epoch, latent_dim)\n","\n","# Optionally, save the trained models\n","generator.save(\"generator_model.h5\")\n","discriminator.save(\"discriminator_model.h5\")"]}]}